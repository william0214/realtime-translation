import { describe, expect, it } from "vitest";
import { transcribeAudio } from "./translationService";
import fs from "fs";
import path from "path";

/**
 * OpenAI ASR API å–®å…ƒæ¸¬è©¦
 * 
 * æ¸¬è©¦æ‰€æœ‰ 4 å€‹ OpenAI èªéŸ³è½‰æ–‡å­—æ¨¡å‹ï¼š
 * 1. whisper-1 - Whisper ç³»åˆ—çš„ API å…¥å£
 * 2. gpt-4o-mini-transcribe - è¼ƒçœæˆæœ¬ã€è¼ƒå¿«çš„è½‰éŒ„
 * 3. gpt-4o-transcribe - è¼ƒé«˜å“è³ªè½‰éŒ„
 * 4. gpt-4o-transcribe-diarize - å«èªªè©±è€…è¾¨è­˜/æ¨™è¨˜èˆ‡æ™‚é–“è³‡è¨Š
 * 
 * æ³¨æ„ï¼š
 * - é€™äº›æ¸¬è©¦æœƒå¯¦éš›å‘¼å« OpenAI APIï¼Œæœƒç”¢ç”Ÿè²»ç”¨
 * - éœ€è¦è¨­å®š OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸
 * - æ¸¬è©¦éŸ³æª”éœ€è¦æ”¾åœ¨ test-audio ç›®éŒ„ä¸‹
 */

describe("OpenAI ASR API Tests", () => {
  // æ¸¬è©¦éŸ³æª”è·¯å¾‘ï¼ˆéœ€è¦æº–å‚™æ¸¬è©¦éŸ³æª”ï¼‰
  const testAudioPath = path.join(__dirname, "../test-audio/sample.webm");
  
  // æª¢æŸ¥æ¸¬è©¦éŸ³æª”æ˜¯å¦å­˜åœ¨
  const hasTestAudio = fs.existsSync(testAudioPath);
  
  // å¦‚æœæ²’æœ‰æ¸¬è©¦éŸ³æª”ï¼Œè·³éæ‰€æœ‰æ¸¬è©¦
  if (!hasTestAudio) {
    it.skip("No test audio file found, skipping ASR API tests", () => {
      console.log(`âš ï¸ Test audio file not found: ${testAudioPath}`);
      console.log("Please create a test-audio directory and add a sample.webm file");
    });
    return;
  }

  // è®€å–æ¸¬è©¦éŸ³æª”
  const audioBuffer = fs.readFileSync(testAudioPath);
  const filename = "test-sample.webm";

  /**
   * æ¸¬è©¦ 1: whisper-1 æ¨¡å‹
   * é€™æ˜¯ Whisper ç³»åˆ—çš„ API å…¥å£ï¼Œæœ€ç©©å®šçš„æ¨¡å‹
   */
  it("should transcribe audio using whisper-1 model", async () => {
    const result = await transcribeAudio(audioBuffer, filename, "normal", "whisper-1");
    
    console.log("\n=== whisper-1 çµæœ ===");
    console.log("æ–‡å­—:", result.text);
    console.log("èªè¨€:", result.language);
    console.log("ASR å»¶é²:", result.asrProfile?.duration, "ms");
    
    expect(result.text).toBeTruthy();
    expect(result.text.length).toBeGreaterThan(0);
    expect(result.language).toBeTruthy();
  }, 30000); // 30 ç§’è¶…æ™‚

  /**
   * æ¸¬è©¦ 2: gpt-4o-mini-transcribe æ¨¡å‹
   * è¼ƒçœæˆæœ¬ã€è¼ƒå¿«çš„è½‰éŒ„æ¨¡å‹
   */
  it("should transcribe audio using gpt-4o-mini-transcribe model", async () => {
    const result = await transcribeAudio(audioBuffer, filename, "normal", "gpt-4o-mini-transcribe");
    
    console.log("\n=== gpt-4o-mini-transcribe çµæœ ===");
    console.log("æ–‡å­—:", result.text);
    console.log("èªè¨€:", result.language);
    console.log("ASR å»¶é²:", result.asrProfile?.duration, "ms");
    
    expect(result.text).toBeTruthy();
    expect(result.text.length).toBeGreaterThan(0);
    expect(result.language).toBeTruthy();
  }, 30000);

  /**
   * æ¸¬è©¦ 3: gpt-4o-transcribe æ¨¡å‹
   * è¼ƒé«˜å“è³ªè½‰éŒ„æ¨¡å‹
   */
  it("should transcribe audio using gpt-4o-transcribe model", async () => {
    const result = await transcribeAudio(audioBuffer, filename, "normal", "gpt-4o-transcribe");
    
    console.log("\n=== gpt-4o-transcribe çµæœ ===");
    console.log("æ–‡å­—:", result.text);
    console.log("èªè¨€:", result.language);
    console.log("ASR å»¶é²:", result.asrProfile?.duration, "ms");
    
    expect(result.text).toBeTruthy();
    expect(result.text.length).toBeGreaterThan(0);
    expect(result.language).toBeTruthy();
  }, 30000);

  /**
   * æ¸¬è©¦ 4: gpt-4o-transcribe-diarize æ¨¡å‹
   * å«èªªè©±è€…è¾¨è­˜/æ¨™è¨˜èˆ‡æ™‚é–“è³‡è¨Š
   * æ³¨æ„ï¼šé€™å€‹æ¨¡å‹å¯èƒ½å›å‚³ä¸åŒçš„è³‡æ–™çµæ§‹
   */
  it("should transcribe audio using gpt-4o-transcribe-diarize model", async () => {
    const result = await transcribeAudio(audioBuffer, filename, "normal", "gpt-4o-transcribe-diarize");
    
    console.log("\n=== gpt-4o-transcribe-diarize çµæœ ===");
    console.log("æ–‡å­—:", result.text);
    console.log("èªè¨€:", result.language);
    console.log("ASR å»¶é²:", result.asrProfile?.duration, "ms");
    
    expect(result.text).toBeTruthy();
    expect(result.text.length).toBeGreaterThan(0);
    // diarize æ¨¡å‹å¯èƒ½ä¸å›å‚³ languageï¼Œæ‰€ä»¥ä¸å¼·åˆ¶è¦æ±‚
  }, 30000);

  /**
   * æ¸¬è©¦ 5: æ¯”è¼ƒæ‰€æœ‰æ¨¡å‹çš„æ•ˆèƒ½
   * æ¸¬é‡æ¯å€‹æ¨¡å‹çš„è½‰éŒ„æ™‚é–“å’Œæº–ç¢ºåº¦
   */
  it("should compare performance of all ASR models", async () => {
    const models = [
      "whisper-1",
      "gpt-4o-mini-transcribe",
      "gpt-4o-transcribe",
      "gpt-4o-transcribe-diarize",
    ];

    const results: Array<{
      model: string;
      text: string;
      language: string | undefined;
      duration: number;
    }> = [];

    console.log("\n=== æ•ˆèƒ½æ¯”è¼ƒ ===");
    
    for (const model of models) {
      const startTime = Date.now();
      const result = await transcribeAudio(audioBuffer, filename, "normal", model);
      const duration = Date.now() - startTime;
      
      results.push({
        model,
        text: result.text,
        language: result.language,
        duration,
      });
      
      console.log(`\n${model}:`);
      console.log(`  æ–‡å­—: ${result.text.substring(0, 50)}...`);
      console.log(`  èªè¨€: ${result.language}`);
      console.log(`  å»¶é²: ${duration}ms`);
    }

    // æ‰¾å‡ºæœ€å¿«çš„æ¨¡å‹
    const fastest = results.reduce((prev, current) => 
      prev.duration < current.duration ? prev : current
    );
    
    console.log(`\nğŸ† æœ€å¿«çš„æ¨¡å‹: ${fastest.model} (${fastest.duration}ms)`);
    
    // ç¢ºä¿æ‰€æœ‰æ¨¡å‹éƒ½æœ‰å›å‚³çµæœ
    results.forEach(result => {
      expect(result.text).toBeTruthy();
      expect(result.text.length).toBeGreaterThan(0);
      expect(result.duration).toBeGreaterThan(0);
    });
  }, 120000); // 120 ç§’è¶…æ™‚ï¼ˆæ¸¬è©¦æ‰€æœ‰æ¨¡å‹ï¼‰

  /**
   * æ¸¬è©¦ 6: æ¸¬è©¦ç„¡æ•ˆçš„æ¨¡å‹åç¨±
   * æ‡‰è©²æ‹‹å‡ºéŒ¯èª¤æˆ–ä½¿ç”¨é è¨­æ¨¡å‹
   */
  it("should handle invalid model name gracefully", async () => {
    try {
      const result = await transcribeAudio(audioBuffer, filename, "normal", "invalid-model-name");
      // å¦‚æœæ²’æœ‰æ‹‹å‡ºéŒ¯èª¤ï¼Œæª¢æŸ¥æ˜¯å¦æœ‰å›å‚³çµæœ
      expect(result).toBeDefined();
    } catch (error: any) {
      // é æœŸæœƒæ‹‹å‡ºéŒ¯èª¤
      expect(error).toBeDefined();
      console.log("âœ… æ­£ç¢ºè™•ç†ç„¡æ•ˆæ¨¡å‹åç¨±:", error.message);
    }
  }, 30000);
});

/**
 * ä½¿ç”¨èªªæ˜ï¼š
 * 
 * 1. æº–å‚™æ¸¬è©¦éŸ³æª”ï¼š
 *    mkdir -p test-audio
 *    # å°‡æ¸¬è©¦éŸ³æª”æ”¾åˆ° test-audio/sample.webm
 * 
 * 2. åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦ï¼š
 *    pnpm test server/asr.api.test.ts
 * 
 * 3. åŸ·è¡Œç‰¹å®šæ¸¬è©¦ï¼š
 *    pnpm test server/asr.api.test.ts -t "whisper-1"
 * 
 * 4. æŸ¥çœ‹è©³ç´°è¼¸å‡ºï¼š
 *    pnpm test server/asr.api.test.ts --reporter=verbose
 * 
 * æ³¨æ„äº‹é …ï¼š
 * - é€™äº›æ¸¬è©¦æœƒå¯¦éš›å‘¼å« OpenAI APIï¼Œæœƒç”¢ç”Ÿè²»ç”¨
 * - ç¢ºä¿ OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸å·²è¨­å®š
 * - æ¸¬è©¦éŸ³æª”å»ºè­°ä½¿ç”¨ 1-3 ç§’çš„çŸ­éŸ³æª”
 * - æ¸¬è©¦éŸ³æª”æ ¼å¼ï¼šWebM (opus codec)
 */
